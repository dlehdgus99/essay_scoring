{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f1608f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T03:17:53.522704Z",
     "iopub.status.busy": "2024-06-26T03:17:53.522380Z",
     "iopub.status.idle": "2024-06-26T03:18:31.502792Z",
     "shell.execute_reply": "2024-06-26T03:18:31.501840Z"
    },
    "papermill": {
     "duration": 37.988837,
     "end_time": "2024-06-26T03:18:31.505082",
     "exception": false,
     "start_time": "2024-06-26T03:17:53.516245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: file:///kaggle/input/packages/textstat/\r\n",
      "Processing /kaggle/input/packages/textstat/textstat-0.7.3-py3-none-any.whl\r\n",
      "Processing /kaggle/input/packages/textstat/pyphen-0.15.0-py3-none-any.whl (from textstat)\r\n",
      "Installing collected packages: pyphen, textstat\r\n",
      "Successfully installed pyphen-0.15.0 textstat-0.7.3\r\n",
      "Looking in links: file:///kaggle/input/packages/vaderSentiment/\r\n",
      "Processing /kaggle/input/packages/vaderSentiment/vaderSentiment-3.3.2-py2.py3-none-any.whl\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from vaderSentiment) (2.31.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->vaderSentiment) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->vaderSentiment) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->vaderSentiment) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->vaderSentiment) (2024.2.2)\r\n",
      "Installing collected packages: vaderSentiment\r\n",
      "Successfully installed vaderSentiment-3.3.2\r\n",
      "Looking in links: file:///kaggle/input/packages/pyspellchecker/\r\n",
      "Processing /kaggle/input/packages/pyspellchecker/pyspellchecker-0.8.1-py3-none-any.whl\r\n",
      "Installing collected packages: pyspellchecker\r\n",
      "Successfully installed pyspellchecker-0.8.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install textstat --no-index --find-links=file:///kaggle/input/packages/textstat/ \n",
    "!pip install vaderSentiment --no-index --find-links=file:///kaggle/input/packages/vaderSentiment/ \n",
    "!pip install pyspellchecker --no-index --find-links=file:///kaggle/input/packages/pyspellchecker/     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72f02aa2",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-26T03:18:31.518317Z",
     "iopub.status.busy": "2024-06-26T03:18:31.517997Z",
     "iopub.status.idle": "2024-06-26T03:18:41.101773Z",
     "shell.execute_reply": "2024-06-26T03:18:41.100733Z"
    },
    "papermill": {
     "duration": 9.593389,
     "end_time": "2024-06-26T03:18:41.104189",
     "exception": false,
     "start_time": "2024-06-26T03:18:31.510800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from textstat import textstat\n",
    "import spacy\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from spellchecker import SpellChecker\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d637d658",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T03:18:41.117149Z",
     "iopub.status.busy": "2024-06-26T03:18:41.116601Z",
     "iopub.status.idle": "2024-06-26T03:18:42.316514Z",
     "shell.execute_reply": "2024-06-26T03:18:42.315710Z"
    },
    "papermill": {
     "duration": 1.208976,
     "end_time": "2024-06-26T03:18:42.318760",
     "exception": false,
     "start_time": "2024-06-26T03:18:41.109784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdee06a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T03:18:42.332402Z",
     "iopub.status.busy": "2024-06-26T03:18:42.332102Z",
     "iopub.status.idle": "2024-06-26T03:18:42.359440Z",
     "shell.execute_reply": "2024-06-26T03:18:42.358679Z"
    },
    "papermill": {
     "duration": 0.037018,
     "end_time": "2024-06-26T03:18:42.361393",
     "exception": false,
     "start_time": "2024-06-26T03:18:42.324375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def textstat_features(text):\n",
    "    features = {}\n",
    "    features['flesch_reading_ease'] = textstat.flesch_reading_ease(text)\n",
    "    features['flesch_kincaid_grade'] = textstat.flesch_kincaid_grade(text)\n",
    "    features['smog_index'] = textstat.smog_index(text)\n",
    "    features['coleman_liau_index'] = textstat.coleman_liau_index(text)\n",
    "    features['automated_readability_index'] = textstat.automated_readability_index(text)\n",
    "    features['dale_chall_readability_score'] = textstat.dale_chall_readability_score(text)\n",
    "    features['difficult_words'] = textstat.difficult_words(text)\n",
    "    features['linsear_write_formula'] = textstat.linsear_write_formula(text)\n",
    "    features['gunning_fog'] = textstat.gunning_fog(text)\n",
    "    features['text_standard'] = textstat.text_standard(text, float_output=True)\n",
    "    features['spache_readability'] = textstat.spache_readability(text)\n",
    "    features['mcalpine_eflaw'] = textstat.mcalpine_eflaw(text)\n",
    "    features['reading_time'] = textstat.reading_time(text)\n",
    "    features['syllable_count'] = textstat.syllable_count(text)\n",
    "    features['lexicon_count'] = textstat.lexicon_count(text)\n",
    "    features['monosyllabcount'] = textstat.monosyllabcount(text)\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "\n",
    "def spelling_features(text):\n",
    "    spell = SpellChecker()\n",
    "\n",
    "    features = {}\n",
    "\n",
    "    words = nltk.word_tokenize(text)\n",
    "    misspelled = spell.unknown(words)\n",
    "\n",
    "    misspelled_count = len(misspelled)\n",
    "    misspelled_ratio = misspelled_count / len(words)\n",
    "    \n",
    "    features['misspelled_count'] = misspelled_count\n",
    "    features['misspelled_count'] = misspelled_ratio\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def extract_linguistic_features(text):\n",
    "\n",
    "    doc = nlp(text)\n",
    "    features = {}\n",
    "\n",
    "\n",
    "    # tense features\n",
    "    tenses = [i.morph.get(\"Tense\") for i in doc]\n",
    "    tenses = [i[0] for i in tenses if i]\n",
    "    tense_counts = Counter(tenses)\n",
    "    features['past_tense_ratio'] = tense_counts.get(\"Past\", 0) / (tense_counts.get(\"Pres\", 0) + tense_counts.get(\"Past\", 0) + 1e-5)\n",
    "    features['present_tense_ratio'] = tense_counts.get(\"Pres\", 0) / (tense_counts.get(\"Pres\", 0) + tense_counts.get(\"Past\", 0) + 1e-5)\n",
    "    \n",
    "    \n",
    "    # len features\n",
    "\n",
    "    features['word_count'] = len(doc)\n",
    "    features['sentence_count'] = len([sentence for sentence in doc.sents])\n",
    "    features['words_per_sentence'] = features['word_count'] / features['sentence_count']\n",
    "    features['std_words_per_sentence'] = np.std([len(sentence) for sentence in doc.sents])\n",
    "\n",
    "    features['unique_words'] = len(set([token.text for token in doc]))\n",
    "    features['lexical_diversity'] = features['unique_words'] / features['word_count']\n",
    "\n",
    "    paragraph = text.split('\\n\\n')\n",
    "\n",
    "    features['paragraph_count'] = len(paragraph)\n",
    "\n",
    "    features['avg_chars_by_paragraph'] = np.mean([len(paragraph) for paragraph in paragraph])\n",
    "    features['avg_words_by_paragraph'] = np.mean([len(nltk.word_tokenize(paragraph)) for paragraph in paragraph])\n",
    "    features['avg_sentences_by_paragraph'] = np.mean([len(nltk.sent_tokenize(paragraph)) for paragraph in paragraph]) \n",
    "\n",
    "    \n",
    "    \n",
    "    # sentiment features\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "    compound_scores, negative_scores, positive_scores, neutral_scores = [], [], [], []\n",
    "    for sentence in sentences:\n",
    "        scores = analyzer.polarity_scores(sentence)\n",
    "        compound_scores.append(scores['compound'])\n",
    "        negative_scores.append(scores['neg'])\n",
    "        positive_scores.append(scores['pos'])\n",
    "        neutral_scores.append(scores['neu'])\n",
    "\n",
    "    features[\"mean_compound\"] = np.mean(compound_scores)\n",
    "    features[\"mean_negative\"] = np.mean(negative_scores)\n",
    "    features[\"mean_positive\"] = np.mean(positive_scores)\n",
    "    features[\"mean_neutral\"] = np.mean(neutral_scores)\n",
    "\n",
    "    features[\"std_compound\"] = np.std(compound_scores)\n",
    "    features[\"std_negative\"] = np.std(negative_scores)\n",
    "    features[\"std_positive\"] = np.std(positive_scores)\n",
    "    features[\"std_neutral\"] = np.std(neutral_scores)\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "\n",
    "def extract_features(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    \n",
    "    # Length-based features\n",
    "    num_words = len(tokens)\n",
    "    num_sentences = textstat.sentence_count(text)\n",
    "    avg_sentence_length = num_words / num_sentences if num_sentences != 0 else 0\n",
    "    \n",
    "    # Readability features\n",
    "    readability = textstat.flesch_reading_ease(text)\n",
    "    \n",
    "    # Text complexity\n",
    "    doc = nlp(text)\n",
    "    num_clauses = sum([1 for token in doc if token.dep_ == 'ROOT'])\n",
    "    avg_clause_length = num_words / num_clauses if num_clauses != 0 else 0\n",
    "    \n",
    "    # Text variation\n",
    "    unique_words = len(set(tokens))\n",
    "    pos_counts = nltk.FreqDist(tag for (word, tag) in pos_tags)\n",
    "    \n",
    "    \n",
    "    features = {\n",
    "        'num_words': num_words,\n",
    "        'num_sentences': num_sentences,\n",
    "        'avg_sentence_length': avg_sentence_length,\n",
    "        'readability': readability,\n",
    "        'num_clauses': num_clauses,\n",
    "        'avg_clause_length': avg_clause_length,\n",
    "        'unique_words': unique_words,\n",
    "        'pos_tags': pos_tags,\n",
    "        'pos_counts': dict(pos_counts),\n",
    "    }\n",
    "    \n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a853cac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T03:18:42.373772Z",
     "iopub.status.busy": "2024-06-26T03:18:42.373434Z",
     "iopub.status.idle": "2024-06-26T03:18:42.386845Z",
     "shell.execute_reply": "2024-06-26T03:18:42.386138Z"
    },
    "papermill": {
     "duration": 0.021996,
     "end_time": "2024-06-26T03:18:42.388951",
     "exception": false,
     "start_time": "2024-06-26T03:18:42.366955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "not_feature_list = ['essay_id', 'full_text', 'score', 'pos_counts','pos_tags']\n",
    "\n",
    "def flatten_features(train_data):\n",
    "    \n",
    "    # Extract the feature columns\n",
    "    feature_columns = [col for col in train_data.columns if col not in not_feature_list]\n",
    "    \n",
    "    print(feature_columns)\n",
    "    # Flatten the features for each row\n",
    "    flattened_features = train_data[feature_columns].values.tolist()\n",
    "    \n",
    "    # Convert each list of features to a PyTorch tensor\n",
    "    flattened_features_tensors = [torch.tensor(features, dtype=torch.float32) for features in flattened_features]\n",
    "    \n",
    "    # Add the new column to the DataFrame\n",
    "    train_data['flattened_features'] = flattened_features_tensors\n",
    "    \n",
    "    \n",
    "    return train_data\n",
    "\n",
    "\n",
    "def extract_all_feature(train_data):\n",
    "    \n",
    "    print('extracting all features')\n",
    "    train_data['textstat_features'] = train_data['full_text'].apply(textstat_features)\n",
    "    train_textstat = pd.DataFrame(train_data['textstat_features'].tolist())\n",
    "    train_data = train_data.drop(columns=['textstat_features'])\n",
    "    train_data = pd.concat([train_data, train_textstat], axis=1)\n",
    "    \n",
    "        \n",
    "    train_data['spelling_features'] = train_data['full_text'].apply(spelling_features)\n",
    "    spell_check_df = pd.DataFrame(train_data['spelling_features'].tolist(), columns=['misspelled_count', 'misspelled_ratio'])\n",
    "    train_data = train_data.drop(columns=['spelling_features'])\n",
    "    train_data = pd.concat([train_data, spell_check_df], axis=1)\n",
    "\n",
    "    \n",
    "    train_data['linguistic_features'] = train_data['full_text'].apply(extract_linguistic_features)\n",
    "    train_linguistic = pd.json_normalize(train_data['linguistic_features'])\n",
    "    train_data = train_data.drop(columns=['linguistic_features'])\n",
    "    train_data = pd.concat([train_data, train_linguistic], axis=1)\n",
    "    \n",
    "    train_data['core_features'] = train_data['full_text'].apply(extract_features)\n",
    "    core_df = pd.DataFrame(train_data['core_features'].tolist())\n",
    "    train_data = train_data.drop(columns=['core_features'])\n",
    "    train_data = pd.concat([train_data, core_df], axis=1)    \n",
    "    \n",
    "    return train_data\n",
    "\n",
    "\n",
    "\n",
    "def select_features(train_data,features=[]):\n",
    "    train_data = train_data.drop(columns=list(set(train_data.columns)-set(features)))\n",
    "    return train_data\n",
    "    \n",
    "\n",
    "def normalize_features(train_data,features_to_normalize=[]):\n",
    "    train_data[features_to_normalize] = minmax_scale(train_data[features_to_normalize])\n",
    "    return train_data\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e2a7ba7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T03:18:42.401361Z",
     "iopub.status.busy": "2024-06-26T03:18:42.400712Z",
     "iopub.status.idle": "2024-06-26T03:18:42.406742Z",
     "shell.execute_reply": "2024-06-26T03:18:42.405892Z"
    },
    "papermill": {
     "duration": 0.014284,
     "end_time": "2024-06-26T03:18:42.408718",
     "exception": false,
     "start_time": "2024-06-26T03:18:42.394434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_to_use = [\n",
    "'flesch_reading_ease',\n",
    "'flesch_kincaid_grade',\n",
    "'smog_index',\n",
    "'coleman_liau_index',\n",
    "'automated_readability_index',\n",
    "'dale_chall_readability_score',\n",
    "'difficult_words',\n",
    "'linsear_write_formula',\n",
    "'gunning_fog',\n",
    "'text_standard',\n",
    "'spache_readability',\n",
    "'mcalpine_eflaw',\n",
    "'reading_time',\n",
    "'syllable_count',\n",
    "'lexicon_count',\n",
    "'monosyllabcount',\n",
    "'misspelled_count',\n",
    "'misspelled_count',\n",
    "'past_tense_ratio',\n",
    "'present_tense_ratio',\n",
    "'word_count',\n",
    "'sentence_count',\n",
    "'words_per_sentence',\n",
    "'std_words_per_sentence',\n",
    "'unique_words',\n",
    "'lexical_diversity',\n",
    "'paragraph_count',\n",
    "'avg_chars_by_paragraph',\n",
    "'avg_words_by_paragraph',\n",
    "'avg_sentences_by_paragraph',\n",
    "'num_words',\n",
    "'num_sentences',\n",
    "'avg_sentence_length',\n",
    "'readability',\n",
    "'num_clauses',\n",
    "'avg_clause_length',\n",
    "'unique_words',\n",
    "\"mean_compound\",\n",
    "\"mean_negative\",\n",
    "\"mean_positive\",\n",
    "\"mean_neutral\",\n",
    "\"std_compound\",\n",
    "\"std_negative\",\n",
    "\"std_positive\",\n",
    "\"std_neutral\",\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6561970a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T03:18:42.420661Z",
     "iopub.status.busy": "2024-06-26T03:18:42.420108Z",
     "iopub.status.idle": "2024-06-26T03:18:42.435382Z",
     "shell.execute_reply": "2024-06-26T03:18:42.434709Z"
    },
    "papermill": {
     "duration": 0.023088,
     "end_time": "2024-06-26T03:18:42.437253",
     "exception": false,
     "start_time": "2024-06-26T03:18:42.414165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pos2idx = pickle.load(open('/kaggle/input/aes-lstm/pos2idx','rb'))\n",
    "\n",
    "\n",
    "\n",
    "class EssayDataset(Dataset):\n",
    "    def __init__(self, data, pos2idx):\n",
    "        self.data = data\n",
    "        self.pos2idx = pos2idx\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        essay = self.data.iloc[idx]\n",
    "        l = []\n",
    "        for token, pos_tag in essay['pos_tags']:\n",
    "            l.append(self.pos2idx.get(pos_tag, 0))\n",
    "        pos_tags = torch.tensor(l,dtype=torch.long)\n",
    "        flattened_features = essay['flattened_features']\n",
    "        return pos_tags, flattened_features\n",
    "    \n",
    "def collate_fn(batch):\n",
    "    pos_tags, features = zip(*batch)\n",
    "    \n",
    "    pos_tags_padded = nn.utils.rnn.pad_sequence(pos_tags, batch_first=True, padding_value=0).to(device)\n",
    "    \n",
    "    features_padded = torch.stack(features).to(device)\n",
    "    \n",
    "    return pos_tags_padded, features_padded\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b2b213c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T03:18:42.449206Z",
     "iopub.status.busy": "2024-06-26T03:18:42.448542Z",
     "iopub.status.idle": "2024-06-26T03:18:43.882881Z",
     "shell.execute_reply": "2024-06-26T03:18:43.881891Z"
    },
    "papermill": {
     "duration": 1.442438,
     "end_time": "2024-06-26T03:18:43.885014",
     "exception": false,
     "start_time": "2024-06-26T03:18:42.442576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting all features\n",
      "['flesch_reading_ease', 'flesch_kincaid_grade', 'smog_index', 'coleman_liau_index', 'automated_readability_index', 'dale_chall_readability_score', 'difficult_words', 'linsear_write_formula', 'gunning_fog', 'text_standard', 'spache_readability', 'mcalpine_eflaw', 'reading_time', 'syllable_count', 'lexicon_count', 'monosyllabcount', 'misspelled_count', 'past_tense_ratio', 'present_tense_ratio', 'word_count', 'sentence_count', 'words_per_sentence', 'std_words_per_sentence', 'unique_words', 'lexical_diversity', 'paragraph_count', 'avg_chars_by_paragraph', 'avg_words_by_paragraph', 'avg_sentences_by_paragraph', 'mean_compound', 'mean_negative', 'mean_positive', 'mean_neutral', 'std_compound', 'std_negative', 'std_positive', 'std_neutral', 'num_words', 'num_sentences', 'avg_sentence_length', 'readability', 'num_clauses', 'avg_clause_length', 'unique_words']\n"
     ]
    }
   ],
   "source": [
    "test_dir = '/kaggle/input/learning-agency-lab-automated-essay-scoring-2/test.csv' \n",
    "test_data = pd.read_csv(test_dir)\n",
    "\n",
    "test_data = extract_all_feature(test_data)\n",
    "test_data = select_features(test_data,features_to_use+not_feature_list)\n",
    "test_data = normalize_features(test_data,features_to_use)\n",
    "test_data = flatten_features(test_data)\n",
    "\n",
    "\n",
    "\n",
    "test_dataset = EssayDataset(test_data, pos2idx)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c177bc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T03:18:43.897489Z",
     "iopub.status.busy": "2024-06-26T03:18:43.897193Z",
     "iopub.status.idle": "2024-06-26T03:18:44.076029Z",
     "shell.execute_reply": "2024-06-26T03:18:44.075097Z"
    },
    "papermill": {
     "duration": 0.187477,
     "end_time": "2024-06-26T03:18:44.077951",
     "exception": false,
     "start_time": "2024-06-26T03:18:43.890474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.attention = nn.Linear(hidden_dim, 1, bias=False)\n",
    "    \n",
    "    def forward(self, lstm_output):\n",
    "        attn_weights = F.softmax(self.attention(lstm_output), dim=1)\n",
    "        context = torch.bmm(attn_weights.transpose(1, 2), lstm_output)\n",
    "        return context.squeeze(1), attn_weights\n",
    "\n",
    "class EssayScoringModel(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, feature_dim, dropout_prob):\n",
    "        super(EssayScoringModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(embedding_dim, hidden_dim, kernel_size=5, padding='same')\n",
    "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.lstm_attention = Attention(hidden_dim*2)\n",
    "        self.conv1_attention = Attention(hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        \n",
    "        \n",
    "\n",
    "        self.fc1 = nn.Linear(hidden_dim * 2 + feature_dim, 256)  # Increased capacity\n",
    "        self.fc2 = nn.Linear(256, 128)  # Added another fully connected layer\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, pos_tags, features):\n",
    "        # Embedding layer\n",
    "        embeds = F.one_hot(pos_tags, num_classes=50).float()  # Shape: (batch_size, seq_length, num_classes)\n",
    "\n",
    "        # Convolutional layer\n",
    "        conv_out = F.relu(self.conv1(embeds.transpose(1, 2)))  # Shape: (batch_size, hidden_dim, seq_length)\n",
    "        conv_out = self.dropout(conv_out)\n",
    "        \n",
    "        # Attention pooling after convolution\n",
    "        attn_conv_out = self.conv1_attention(conv_out.transpose(1, 2))[0]  # Shape: (batch_size, hidden_dim)\n",
    "        \n",
    "        # LSTM layer\n",
    "        lstm_out, _ = self.lstm(attn_conv_out.unsqueeze(1))  # Shape: (batch_size, 1, hidden_dim)\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        \n",
    "        # Attention pooling after LSTM\n",
    "        attn_lstm_out = self.lstm_attention(lstm_out)[0]  # Shape: (batch_size, hidden_dim * 2)\n",
    "        \n",
    "        # Concatenate LSTM output with additional features\n",
    "        combined = torch.cat((attn_lstm_out, features), dim=1)  # Shape: (batch_size, hidden_dim * 2 + feature_dim)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        x = F.relu(self.fc1(combined))  # Shape: (batch_size, 256)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))  # Shape: (batch_size, 128)\n",
    "        x = self.fc3(x)  # Shape: (batch_size, 1)\n",
    "        x = torch.sigmoid(x) * 5 + 1  # scores are between 1 and 6\n",
    "        \n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fb42f34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T03:18:44.090346Z",
     "iopub.status.busy": "2024-06-26T03:18:44.090050Z",
     "iopub.status.idle": "2024-06-26T03:18:44.399272Z",
     "shell.execute_reply": "2024-06-26T03:18:44.398291Z"
    },
    "papermill": {
     "duration": 0.317707,
     "end_time": "2024-06-26T03:18:44.401253",
     "exception": false,
     "start_time": "2024-06-26T03:18:44.083546",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EssayScoringModel(\n",
       "  (conv1): Conv1d(50, 100, kernel_size=(5,), stride=(1,), padding=same)\n",
       "  (lstm): LSTM(100, 100, batch_first=True, bidirectional=True)\n",
       "  (lstm_attention): Attention(\n",
       "    (attention): Linear(in_features=200, out_features=1, bias=False)\n",
       "  )\n",
       "  (conv1_attention): Attention(\n",
       "    (attention): Linear(in_features=100, out_features=1, bias=False)\n",
       "  )\n",
       "  (dropout): Dropout(p=0, inplace=False)\n",
       "  (fc1): Linear(in_features=246, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "POS Embeddings Output Vector Dimensions 50\n",
    "ConvolutionalLayer\n",
    "Number of Filters 100\n",
    "Filter Length 5\n",
    "LSTM Layer Output Dimensions 100\n",
    "Dropout Probability 0.5\n",
    "Non Prompt-specific Features Vector Dimensions 86\n",
    "\n",
    "'''\n",
    "\n",
    "class ModelParameters:\n",
    "    def __init():\n",
    "        pass\n",
    "\n",
    "model_parameters = pickle.load(open('/kaggle/input/aes-lstm/model_parameters','rb'))\n",
    "\n",
    "embedding_dim = model_parameters.embedding_dim \n",
    "hidden_dim = model_parameters.hidden_dim \n",
    "feature_dim = model_parameters.feature_dim\n",
    "\n",
    "model = EssayScoringModel(embedding_dim, hidden_dim, feature_dim,dropout_prob=0).to(device)\n",
    "model.load_state_dict(torch.load('/kaggle/input/aes-lstm/essay_scoring_best_model.pth'))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1676cf5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T03:18:44.413753Z",
     "iopub.status.busy": "2024-06-26T03:18:44.413427Z",
     "iopub.status.idle": "2024-06-26T03:18:45.057100Z",
     "shell.execute_reply": "2024-06-26T03:18:45.056095Z"
    },
    "papermill": {
     "duration": 0.652227,
     "end_time": "2024-06-26T03:18:45.059155",
     "exception": false,
     "start_time": "2024-06-26T03:18:44.406928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for pos_tags, features in test_loader:\n",
    "        output = model(pos_tags, features).squeeze()\n",
    "        test_preds.append(float(output))\n",
    "\n",
    "test_data['score'] = [round(pred) for pred in test_preds]\n",
    "submission = test_data[['essay_id', 'score']]\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"Submission file created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13374e34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T03:18:45.071993Z",
     "iopub.status.busy": "2024-06-26T03:18:45.071368Z",
     "iopub.status.idle": "2024-06-26T03:18:45.083810Z",
     "shell.execute_reply": "2024-06-26T03:18:45.082689Z"
    },
    "papermill": {
     "duration": 0.020938,
     "end_time": "2024-06-26T03:18:45.085823",
     "exception": false,
     "start_time": "2024-06-26T03:18:45.064885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id  score\n",
       "0  000d118      1\n",
       "1  000fe60      2\n",
       "2  001ab80      5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8059942,
     "sourceId": 71485,
     "sourceType": "competition"
    },
    {
     "datasetId": 5046300,
     "sourceId": 8784268,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 185346871,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 56.051892,
   "end_time": "2024-06-26T03:18:46.814529",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-26T03:17:50.762637",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
